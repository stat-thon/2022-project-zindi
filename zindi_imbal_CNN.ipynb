{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zindi Image classification (Binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as img # to read images\n",
    "\n",
    "import os                      # to generate new file directories\n",
    "import shutil                  # to move files\n",
    "from tqdm import tqdm          # to see process bar\n",
    "\n",
    "import glob                    # to gather jpg files\n",
    "from glob import glob\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input your own file directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input your file directory\n",
    "\n",
    "file_dir = 'D:/thon/DL/zindi' # Change here with your file directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of New_train data is  891\n",
      "               Image_id  Label\n",
      "0  id_02mh3w48pmyc9.jpg      0\n",
      "1  id_02rpb463h9d3w.jpg      0\n",
      "2  id_02wc3jeeao8ol.jpg      1\n",
      "3  id_04xrxyd43rlgz.jpg      0\n",
      "4  id_082w0qygo3eth.jpg      0\n",
      "\n",
      "\n",
      "               Image_id\n",
      "0  id_00exusbkgzw1b.jpg\n",
      "1  id_03dqinf6w0znv.jpg\n",
      "2  id_046yl0cxn3ybz.jpg\n",
      "3  id_04athdtx2abyg.jpg\n",
      "4  id_062aauf9e9jk0.jpg\n",
      "\n",
      "\n",
      "The number of test data is  1080\n",
      "1080\n"
     ]
    }
   ],
   "source": [
    "# Read train, test and submission csv files\n",
    "\n",
    "train_df = pd.read_csv(file_dir + '/New_Train.csv')\n",
    "test_df = pd.read_csv(file_dir + '/Test.csv')\n",
    "sample_sub = pd.read_csv(file_dir + '/SampleSubmission.csv')\n",
    "\n",
    "print(\"The number of New_train data is \", len(train_df['Image_id']))\n",
    "print(train_df.head())\n",
    "print('\\n')\n",
    "print(test_df.head())\n",
    "print('\\n')\n",
    "print(\"The number of test data is \", len(test_df['Image_id']))\n",
    "print(np.sum(test_df['Image_id'] == sample_sub['Image_id'])) # Test.csv and SampleSubmission.csv's Image_id is identical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Managing Image directories and files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## You don't need to do it twice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "### You don't need to do it twice\n",
    "\n",
    "# Set an image directory\n",
    "img_dir = file_dir + '/Images'\n",
    "\n",
    "# Set train and test directories\n",
    "\n",
    "train_dir = img_dir + '/imbalanced_train'\n",
    "test_dir = img_dir + '/test'\n",
    "\n",
    "# Generate '0' / '1' label folder in 'train' folder\n",
    "\n",
    "os.makedirs(train_dir + '/1')\n",
    "os.makedirs(train_dir + '/0')\n",
    "\n",
    "# Set train label 0 and 1 directories\n",
    "\n",
    "train1_dir = train_dir + '/1'\n",
    "train0_dir = train_dir + '/0'\n",
    "\n",
    "\n",
    "### To move files according to train.csv and test.csv's 'Image_id' column\n",
    "\n",
    "train_file_name = train_df[\"Image_id\"]\n",
    "train_file_label = train_df[\"Label\"]\n",
    "\n",
    "# Separate train images to '0' / '1' label folder\n",
    "\n",
    "for i, name in enumerate(train_file_name):\n",
    "    file_source = train_dir + f'/{name}'\n",
    "    file_destination_1 = train1_dir # for Label 1\n",
    "    file_destination_0 = train0_dir # for Label 0\n",
    "\n",
    "    if train_file_label[i] == 1:\n",
    "        shutil.move(file_source, file_destination_1)\n",
    "    else:\n",
    "        shutil.move(file_source, file_destination_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 891 files belonging to 2 classes.\n",
      "Using 713 files for training.\n",
      "\n",
      "\n",
      "Found 891 files belonging to 2 classes.\n",
      "Using 178 files for validation.\n",
      "\n",
      "\n",
      "Found 1080 files belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "### Image preprocessing\n",
    "# Set batch_size, img_height, img_width\n",
    "\n",
    "batch_size = 32\n",
    "img_height = 180\n",
    "img_width = 180\n",
    "\n",
    "\n",
    "# Train image dataset\n",
    "\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    train_dir,\n",
    "    validation_split = 0.2, # 891 * 0.8 = 713 images are for train dataset\n",
    "    label_mode = 'binary',\n",
    "    subset = 'training',\n",
    "    shuffle = True,\n",
    "    seed = 2021120087,\n",
    "    image_size = (img_height, img_width),\n",
    "    batch_size = batch_size)\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "# Validation image dataset\n",
    "\n",
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    train_dir,\n",
    "    validation_split = 0.2, # 891 * 0.2 = 178 images are for validation dataset\n",
    "    label_mode = 'binary',\n",
    "    subset = \"validation\",\n",
    "    shuffle = True,\n",
    "    seed = 2021120087,\n",
    "    image_size = (img_height, img_width),\n",
    "    batch_size = batch_size)\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "# Test image dataset\n",
    "\n",
    "test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    test_dir,\n",
    "    label_mode = None,\n",
    "    shuffle = False,\n",
    "    image_size = (img_height, img_width),\n",
    "    batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0', '1']\n",
      "(32, 180, 180, 3)\n",
      "(32, 1)\n"
     ]
    }
   ],
   "source": [
    "# Class names (Labels)\n",
    "\n",
    "class_names = train_ds.class_names\n",
    "print(class_names)\n",
    "\n",
    "\n",
    "# Check the train image shapes\n",
    "\n",
    "for image_batch, labels_batch in train_ds:\n",
    "    print(image_batch.shape)\n",
    "    print(labels_batch.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Model using tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 180, 180, 3)]     0         \n",
      "_________________________________________________________________\n",
      "rescaling_2 (Rescaling)      (None, 180, 180, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 178, 178, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 89, 89, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 87, 87, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 43, 43, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 41, 41, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 20, 20, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 18, 18, 256)       295168    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 9, 9, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 7, 7, 256)         590080    \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 12544)             0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 12545     \n",
      "=================================================================\n",
      "Total params: 991,041\n",
      "Trainable params: 991,041\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# ConvNet layers\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "inputs = keras.Input(shape = (180, 180, 3))\n",
    "x = layers.experimental.preprocessing.Rescaling(1./255)(inputs)\n",
    "x = layers.Conv2D(filters = 32, kernel_size = 3, activation = \"relu\")(x)\n",
    "x = layers.MaxPooling2D(pool_size = 2)(x)\n",
    "x = layers.Conv2D(filters = 64, kernel_size = 3, activation = \"relu\")(x)\n",
    "x = layers.MaxPooling2D(pool_size = 2)(x)\n",
    "x = layers.Conv2D(filters = 128, kernel_size = 3, activation = \"relu\")(x)\n",
    "x = layers.MaxPooling2D(pool_size = 2)(x)\n",
    "x = layers.Conv2D(filters = 256, kernel_size = 3, activation = \"relu\")(x)\n",
    "x = layers.MaxPooling2D(pool_size = 2)(x)\n",
    "x = layers.Conv2D(filters = 256, kernel_size = 3, activation = \"relu\")(x)\n",
    "x = layers.Flatten()(x)\n",
    "outputs = layers.Dense(1, activation = \"sigmoid\")(x)\n",
    "model = keras.Model(inputs = inputs, outputs = outputs)\n",
    "\n",
    "# Model summary\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "23/23 [==============================] - 3s 96ms/step - loss: 0.3425 - auc: 0.5557 - val_loss: 0.5058 - val_auc: 0.6761\n",
      "Epoch 2/20\n",
      "23/23 [==============================] - 2s 88ms/step - loss: 0.3613 - auc: 0.5436 - val_loss: 0.3083 - val_auc: 0.5802\n",
      "Epoch 3/20\n",
      "23/23 [==============================] - 2s 88ms/step - loss: 0.3129 - auc: 0.5643 - val_loss: 0.3658 - val_auc: 0.6786\n",
      "Epoch 4/20\n",
      "23/23 [==============================] - 2s 89ms/step - loss: 0.3048 - auc: 0.6298 - val_loss: 0.2922 - val_auc: 0.6603\n",
      "Epoch 5/20\n",
      "23/23 [==============================] - 2s 89ms/step - loss: 0.2482 - auc: 0.7995 - val_loss: 0.2722 - val_auc: 0.7822\n",
      "Epoch 6/20\n",
      "23/23 [==============================] - 2s 88ms/step - loss: 0.2353 - auc: 0.8490 - val_loss: 0.3127 - val_auc: 0.7834\n",
      "Epoch 7/20\n",
      "23/23 [==============================] - 2s 88ms/step - loss: 0.2424 - auc: 0.8249 - val_loss: 0.2791 - val_auc: 0.7822\n",
      "Epoch 8/20\n",
      "23/23 [==============================] - 2s 88ms/step - loss: 0.1647 - auc: 0.9271 - val_loss: 0.2375 - val_auc: 0.8239\n",
      "Epoch 9/20\n",
      "23/23 [==============================] - 2s 88ms/step - loss: 0.1554 - auc: 0.9304 - val_loss: 0.2344 - val_auc: 0.8164\n",
      "Epoch 10/20\n",
      "23/23 [==============================] - 2s 87ms/step - loss: 0.1252 - auc: 0.9603 - val_loss: 0.2796 - val_auc: 0.8152\n",
      "Epoch 11/20\n",
      "23/23 [==============================] - 2s 87ms/step - loss: 0.1052 - auc: 0.9669 - val_loss: 0.4058 - val_auc: 0.7442\n",
      "Epoch 12/20\n",
      "23/23 [==============================] - 2s 88ms/step - loss: 0.1343 - auc: 0.9543 - val_loss: 0.2429 - val_auc: 0.8412\n",
      "Epoch 13/20\n",
      "23/23 [==============================] - 2s 87ms/step - loss: 0.0913 - auc: 0.9819 - val_loss: 0.2879 - val_auc: 0.8258\n",
      "Epoch 14/20\n",
      "23/23 [==============================] - 2s 87ms/step - loss: 0.0737 - auc: 0.9814 - val_loss: 0.2919 - val_auc: 0.8094\n",
      "Epoch 15/20\n",
      "23/23 [==============================] - 2s 87ms/step - loss: 0.0585 - auc: 0.9959 - val_loss: 0.3412 - val_auc: 0.8166\n",
      "Epoch 16/20\n",
      "23/23 [==============================] - 2s 87ms/step - loss: 0.0396 - auc: 0.9968 - val_loss: 0.3812 - val_auc: 0.7888\n",
      "Epoch 17/20\n",
      "23/23 [==============================] - 2s 88ms/step - loss: 0.0663 - auc: 0.9840 - val_loss: 0.4065 - val_auc: 0.7008\n",
      "Epoch 18/20\n",
      "23/23 [==============================] - 2s 88ms/step - loss: 0.0436 - auc: 0.9967 - val_loss: 0.3826 - val_auc: 0.7670\n",
      "Epoch 19/20\n",
      "23/23 [==============================] - 2s 87ms/step - loss: 0.0678 - auc: 0.9900 - val_loss: 0.4345 - val_auc: 0.7272\n",
      "Epoch 20/20\n",
      "23/23 [==============================] - 2s 87ms/step - loss: 0.0642 - auc: 0.9841 - val_loss: 0.4859 - val_auc: 0.6898\n"
     ]
    }
   ],
   "source": [
    "# Compile model\n",
    "\n",
    "model.compile(\n",
    "    optimizer = 'adam',\n",
    "    loss = 'binary_crossentropy',\n",
    "    metrics = ['AUC']\n",
    ")\n",
    "\n",
    "# Train model\n",
    "\n",
    "history = model.fit(train_ds, validation_data = val_ds, epochs = 20, batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize validation loss and accuracy loss\n",
    "\n",
    "history_dict = history.history\n",
    "loss_values = history_dict[\"loss\"]\n",
    "val_loss_values = history_dict[\"val_loss\"]\n",
    "epochs = range(1, len(loss_values) + 1)\n",
    "plt.plot(epochs, loss_values, \"bo\", label = \"Training loss\")\n",
    "plt.plot(epochs, val_loss_values, \"b\", label = \"Validation loss\")\n",
    "plt.title(\"Training and validation loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To find the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "23/23 [==============================] - 3s 98ms/step - loss: 0.3841 - auc: 0.4629 - val_loss: 0.3155 - val_auc: 0.5581\n",
      "INFO:tensorflow:Assets written to: convnet.keras.imbalanced\\assets\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 3s 96ms/step - loss: 0.3076 - auc: 0.5590 - val_loss: 0.3098 - val_auc: 0.6497\n",
      "INFO:tensorflow:Assets written to: convnet.keras.imbalanced\\assets\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 3s 96ms/step - loss: 0.3490 - auc: 0.5649 - val_loss: 0.3395 - val_auc: 0.6331\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 2s 89ms/step - loss: 0.3008 - auc: 0.6240 - val_loss: 0.2791 - val_auc: 0.7687\n",
      "INFO:tensorflow:Assets written to: convnet.keras.imbalanced\\assets\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 2s 88ms/step - loss: 0.2598 - auc: 0.7777 - val_loss: 0.2430 - val_auc: 0.8299\n",
      "INFO:tensorflow:Assets written to: convnet.keras.imbalanced\\assets\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 2s 88ms/step - loss: 0.2142 - auc: 0.8723 - val_loss: 0.2548 - val_auc: 0.8243\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 2s 88ms/step - loss: 0.2083 - auc: 0.8684 - val_loss: 0.2262 - val_auc: 0.8397\n",
      "INFO:tensorflow:Assets written to: convnet.keras.imbalanced\\assets\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 2s 87ms/step - loss: 0.1748 - auc: 0.9190 - val_loss: 0.3003 - val_auc: 0.7641s: 0.1651 - auc: 0.9\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 2s 89ms/step - loss: 0.2290 - auc: 0.8337 - val_loss: 0.2423 - val_auc: 0.8615\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 2s 89ms/step - loss: 0.1894 - auc: 0.8941 - val_loss: 0.2280 - val_auc: 0.8439\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 2s 89ms/step - loss: 0.1472 - auc: 0.9312 - val_loss: 0.2409 - val_auc: 0.8343\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 2s 90ms/step - loss: 0.1176 - auc: 0.9714 - val_loss: 0.2449 - val_auc: 0.8600\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 2s 87ms/step - loss: 0.1083 - auc: 0.9707 - val_loss: 0.2569 - val_auc: 0.8233\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 2s 88ms/step - loss: 0.1117 - auc: 0.9664 - val_loss: 0.2477 - val_auc: 0.8389\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 2s 88ms/step - loss: 0.0770 - auc: 0.9884 - val_loss: 0.2962 - val_auc: 0.7905\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 2s 89ms/step - loss: 0.0694 - auc: 0.9807 - val_loss: 0.2890 - val_auc: 0.7921\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 2s 88ms/step - loss: 0.0867 - auc: 0.9834 - val_loss: 0.2482 - val_auc: 0.8387\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 2s 88ms/step - loss: 0.0498 - auc: 0.9941 - val_loss: 0.2053 - val_auc: 0.9103\n",
      "INFO:tensorflow:Assets written to: convnet.keras.imbalanced\\assets\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 2s 88ms/step - loss: 0.0403 - auc: 0.9968 - val_loss: 0.3468 - val_auc: 0.8057\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 2s 88ms/step - loss: 0.0277 - auc: 0.9987 - val_loss: 0.3461 - val_auc: 0.8081\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 2s 87ms/step - loss: 0.0328 - auc: 0.9982 - val_loss: 0.3429 - val_auc: 0.8459\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 2s 88ms/step - loss: 0.0219 - auc: 0.9991 - val_loss: 0.4774 - val_auc: 0.7151\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 2s 89ms/step - loss: 0.0118 - auc: 0.9998 - val_loss: 0.5155 - val_auc: 0.7539\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 2s 88ms/step - loss: 0.0068 - auc: 1.0000 - val_loss: 0.4110 - val_auc: 0.7768\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 2s 87ms/step - loss: 0.0020 - auc: 1.0000 - val_loss: 0.4594 - val_auc: 0.8061\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 2s 88ms/step - loss: 0.0011 - auc: 1.0000 - val_loss: 0.5758 - val_auc: 0.7596\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 2s 87ms/step - loss: 4.7133e-04 - auc: 1.0000 - val_loss: 0.5905 - val_auc: 0.7544\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 2s 87ms/step - loss: 2.0414e-04 - auc: 1.0000 - val_loss: 0.6095 - val_auc: 0.7542\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 2s 88ms/step - loss: 1.4238e-04 - auc: 1.0000 - val_loss: 0.6247 - val_auc: 0.7554\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 2s 87ms/step - loss: 1.1121e-04 - auc: 1.0000 - val_loss: 0.6375 - val_auc: 0.7554\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 2s 88ms/step - loss: 9.3167e-05 - auc: 1.0000 - val_loss: 0.6499 - val_auc: 0.7554\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 2s 87ms/step - loss: 7.9016e-05 - auc: 1.0000 - val_loss: 0.6588 - val_auc: 0.7568\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 2s 87ms/step - loss: 6.7336e-05 - auc: 1.0000 - val_loss: 0.6666 - val_auc: 0.7568\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 2s 88ms/step - loss: 5.7220e-05 - auc: 1.0000 - val_loss: 0.6774 - val_auc: 0.7568\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 2s 87ms/step - loss: 5.1435e-05 - auc: 1.0000 - val_loss: 0.6826 - val_auc: 0.7569\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 2s 86ms/step - loss: 4.5474e-05 - auc: 1.0000 - val_loss: 0.6900 - val_auc: 0.7569\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 2s 88ms/step - loss: 4.0387e-05 - auc: 1.0000 - val_loss: 0.6954 - val_auc: 0.7568\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 2s 88ms/step - loss: 3.6631e-05 - auc: 1.0000 - val_loss: 0.7024 - val_auc: 0.7571\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 2s 88ms/step - loss: 3.3102e-05 - auc: 1.0000 - val_loss: 0.7027 - val_auc: 0.7575A: 0s - loss: 3.3110e-05 - auc: 1.000 - ETA: 0s - loss: 3.3525e-05 - auc: 1.000\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 2s 89ms/step - loss: 3.0151e-05 - auc: 1.0000 - val_loss: 0.7082 - val_auc: 0.7573\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 2s 86ms/step - loss: 2.7817e-05 - auc: 1.0000 - val_loss: 0.7119 - val_auc: 0.7573\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 2s 84ms/step - loss: 2.5711e-05 - auc: 1.0000 - val_loss: 0.7171 - val_auc: 0.7589\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 2s 85ms/step - loss: 2.3780e-05 - auc: 1.0000 - val_loss: 0.7211 - val_auc: 0.7589\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 2s 85ms/step - loss: 2.2019e-05 - auc: 1.0000 - val_loss: 0.7266 - val_auc: 0.7587\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 2s 86ms/step - loss: 2.0818e-05 - auc: 1.0000 - val_loss: 0.7306 - val_auc: 0.7583\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 2s 91ms/step - loss: 1.9197e-05 - auc: 1.0000 - val_loss: 0.7338 - val_auc: 0.7587\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 2s 89ms/step - loss: 1.7916e-05 - auc: 1.0000 - val_loss: 0.7377 - val_auc: 0.7587\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 2s 89ms/step - loss: 1.6754e-05 - auc: 1.0000 - val_loss: 0.7416 - val_auc: 0.7585\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 2s 95ms/step - loss: 1.5803e-05 - auc: 1.0000 - val_loss: 0.7454 - val_auc: 0.7585\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 2s 88ms/step - loss: 1.4784e-05 - auc: 1.0000 - val_loss: 0.7473 - val_auc: 0.7585\n"
     ]
    }
   ],
   "source": [
    "### Find the best model using callbacks\n",
    "# Define model again\n",
    "\n",
    "inputs = keras.Input(shape = (180, 180, 3))\n",
    "x = layers.experimental.preprocessing.Rescaling(1./255)(inputs)\n",
    "x = layers.Conv2D(filters = 32, kernel_size = 3, activation = \"relu\")(x)\n",
    "x = layers.MaxPooling2D(pool_size = 2)(x)\n",
    "x = layers.Conv2D(filters = 64, kernel_size = 3, activation = \"relu\")(x)\n",
    "x = layers.MaxPooling2D(pool_size = 2)(x)\n",
    "x = layers.Conv2D(filters = 128, kernel_size = 3, activation = \"relu\")(x)\n",
    "x = layers.MaxPooling2D(pool_size = 2)(x)\n",
    "x = layers.Conv2D(filters = 256, kernel_size = 3, activation = \"relu\")(x)\n",
    "x = layers.MaxPooling2D(pool_size = 2)(x)\n",
    "x = layers.Conv2D(filters = 256, kernel_size = 3, activation = \"relu\")(x)\n",
    "x = layers.Flatten()(x)\n",
    "outputs = layers.Dense(1, activation = \"sigmoid\")(x)\n",
    "model = keras.Model(inputs = inputs, outputs = outputs)\n",
    "\n",
    "# Compile model\n",
    "\n",
    "model.compile(\n",
    "    optimizer = 'adam',\n",
    "    loss = 'binary_crossentropy',\n",
    "    metrics = ['AUC']\n",
    ")\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath = \"convnet.keras.imbalanced\", # Save the best model as 'convnet.kears.imbalanced'\n",
    "        save_best_only = True,\n",
    "        monitor = \"val_loss\")\n",
    "]\n",
    "\n",
    "history_test = model.fit(\n",
    "    train_ds,\n",
    "    epochs = 50,\n",
    "    validation_data = val_ds,\n",
    "    callbacks = callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.20528709888458252 0.9103009104728699\n"
     ]
    }
   ],
   "source": [
    "print(np.min(history_test.history[\"val_loss\"]), np.max(history_test.history[\"val_auc\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image_id</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_00exusbkgzw1b.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_03dqinf6w0znv.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_046yl0cxn3ybz.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_04athdtx2abyg.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_062aauf9e9jk0.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Image_id  Label\n",
       "0  id_00exusbkgzw1b.jpg      0\n",
       "1  id_03dqinf6w0znv.jpg      0\n",
       "2  id_046yl0cxn3ybz.jpg      1\n",
       "3  id_04athdtx2abyg.jpg      0\n",
       "4  id_062aauf9e9jk0.jpg      0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the best model\n",
    "\n",
    "test_model = keras.models.load_model(\"convnet.keras.imbalanced\")\n",
    "# load the best model which we defined \"convnet.keras\"\n",
    "\n",
    "predictions = test_model.predict(test_ds)\n",
    "prediction_classes = [\n",
    "    1 if prob > 0.5 else 0 for prob in np.ravel(predictions)\n",
    "]\n",
    "\n",
    "sample_sub[\"Label\"] = prediction_classes\n",
    "sample_sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save csv file\n",
    "\n",
    "sample_sub.to_csv(\"Submission_imbal.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "453dee3dc3901cb9a21ed0866384fb1d6a0d6f4710a79aa791e402cd59be06a2"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('tf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
