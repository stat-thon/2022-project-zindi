{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "\n",
    "import os\n",
    "import timm\n",
    "import random\n",
    "import shutil\n",
    "import copy\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from sklearn.metrics import f1_score, accuracy_score, roc_auc_score\n",
    "import time\n",
    "\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed: int = 110):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)  # type: ignore\n",
    "    torch.backends.cudnn.deterministic = True  # type: ignore\n",
    "    torch.backends.cudnn.benchmark = True  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input your own directory\n",
    "\n",
    "file_dir = 'D:/thon/DL/zindi'\n",
    "img_dir = file_dir + '/Images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(file_dir + \"/highly_imbalanced_train.csv\")\n",
    "test_df = pd.read_csv(file_dir + '/Test.csv')\n",
    "train_labels = train_df[\"Label\"]\n",
    "\n",
    "label_unique = sorted(np.unique(train_labels))\n",
    "label_unique = {key:value for key,value in zip(label_unique, range(len(label_unique)))}\n",
    "\n",
    "train_labels = [label_unique[k] for k in train_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    810\n",
       "1      9\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### You don't need to do it twice\n",
    "# Set train and test directories\n",
    "\n",
    "train_dir = img_dir + '/highly_imbalanced_train'\n",
    "test_dir = img_dir + '/test'\n",
    "\n",
    "### To move files according to train.csv and test.csv's 'Image_id' column\n",
    "\n",
    "train_file_name = train_df[\"Image_id\"]\n",
    "train_file_label = train_df[\"Label\"]\n",
    "test_file_name = test_df[\"Image_id\"]\n",
    "\n",
    "# Load Image datasets\n",
    "train_jpg = sorted(glob(train_dir +'/*.jpg'))\n",
    "test_jpg = sorted(glob(test_dir + '/*.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = 224 # input size for efficientnet_b0 : 224 * 224\n",
    "\n",
    "def img_load(path):\n",
    "    img = cv2.imread(path)[:,:,::-1]\n",
    "    img = cv2.resize(img, (img_size, img_size))\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:00<00:00, 79.84it/s]\n",
      "100%|██████████| 1080/1080 [00:15<00:00, 70.66it/s]\n"
     ]
    }
   ],
   "source": [
    "train_imgs = [img_load(m) for m in tqdm(train_jpg)]\n",
    "test_imgs = [img_load(n) for n in tqdm(test_jpg)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Custom_dataset(Dataset):\n",
    "    def __init__(self, img_paths, labels, mode='train'):\n",
    "        self.img_paths = img_paths\n",
    "        self.labels = labels\n",
    "        self.mode=mode\n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)\n",
    "    def __getitem__(self, idx):\n",
    "        img = self.img_paths[idx]\n",
    "        if self.mode=='train':\n",
    "            augmentation = random.randint(0,2)\n",
    "            if augmentation==1:\n",
    "                img = img[::-1].copy()\n",
    "            elif augmentation==2:\n",
    "                img = img[:,::-1].copy()\n",
    "        img = transforms.ToTensor()(img)\n",
    "        if self.mode=='test':\n",
    "            pass\n",
    "        \n",
    "        label = self.labels[idx]\n",
    "        return img, label\n",
    "    \n",
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Network, self).__init__()\n",
    "        self.model = timm.create_model('efficientnet_b0', pretrained=True, num_classes=88)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "epochs = 25\n",
    "\n",
    "# Train\n",
    "train_dataset = Custom_dataset(np.array(train_imgs), np.array(train_labels), mode = 'train')\n",
    "train_loader = DataLoader(train_dataset, shuffle = True, batch_size = batch_size)\n",
    "\n",
    "# Test\n",
    "test_dataset = Custom_dataset(np.array(test_imgs), np.array([\"tmp\"] * len(test_imgs)), mode = 'test')\n",
    "test_loader = DataLoader(test_dataset, shuffle = False, batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1 / 25    time : 0s / 9s\n",
      "TRAIN    loss : 5.39453    F1 : 0.00000\n",
      "epoch : 2 / 25    time : 0s / 8s\n",
      "TRAIN    loss : 5.25391    F1 : 0.00000\n",
      "epoch : 3 / 25    time : 0s / 7s\n",
      "TRAIN    loss : 3.05273    F1 : 0.14286\n",
      "epoch : 4 / 25    time : 0s / 7s\n",
      "TRAIN    loss : 1.25391    F1 : 1.00000\n",
      "epoch : 5 / 25    time : 0s / 7s\n",
      "TRAIN    loss : 0.44385    F1 : 1.00000\n",
      "epoch : 6 / 25    time : 0s / 6s\n",
      "TRAIN    loss : 0.18372    F1 : 1.00000\n",
      "epoch : 7 / 25    time : 0s / 6s\n",
      "TRAIN    loss : 0.10565    F1 : 1.00000\n",
      "epoch : 8 / 25    time : 0s / 6s\n",
      "TRAIN    loss : 0.01605    F1 : 1.00000\n",
      "epoch : 9 / 25    time : 0s / 5s\n",
      "TRAIN    loss : 0.17371    F1 : 1.00000\n",
      "epoch : 10 / 25    time : 0s / 5s\n",
      "TRAIN    loss : 0.00589    F1 : 1.00000\n",
      "epoch : 11 / 25    time : 0s / 5s\n",
      "TRAIN    loss : 0.00351    F1 : 1.00000\n",
      "epoch : 12 / 25    time : 0s / 4s\n",
      "TRAIN    loss : 0.00594    F1 : 1.00000\n",
      "epoch : 13 / 25    time : 0s / 4s\n",
      "TRAIN    loss : 0.00653    F1 : 1.00000\n",
      "epoch : 14 / 25    time : 0s / 4s\n",
      "TRAIN    loss : 0.00316    F1 : 1.00000\n",
      "epoch : 15 / 25    time : 0s / 3s\n",
      "TRAIN    loss : 0.00385    F1 : 1.00000\n",
      "epoch : 16 / 25    time : 0s / 3s\n",
      "TRAIN    loss : 0.00488    F1 : 1.00000\n",
      "epoch : 17 / 25    time : 0s / 3s\n",
      "TRAIN    loss : 0.00162    F1 : 1.00000\n",
      "epoch : 18 / 25    time : 0s / 2s\n",
      "TRAIN    loss : 0.00184    F1 : 1.00000\n",
      "epoch : 19 / 25    time : 0s / 2s\n",
      "TRAIN    loss : 0.00139    F1 : 1.00000\n",
      "epoch : 20 / 25    time : 0s / 2s\n",
      "TRAIN    loss : 0.00087    F1 : 1.00000\n",
      "epoch : 21 / 25    time : 0s / 1s\n",
      "TRAIN    loss : 0.00068    F1 : 1.00000\n",
      "epoch : 22 / 25    time : 0s / 1s\n",
      "TRAIN    loss : 0.00038    F1 : 1.00000\n",
      "epoch : 23 / 25    time : 0s / 1s\n",
      "TRAIN    loss : 0.00035    F1 : 1.00000\n",
      "epoch : 24 / 25    time : 0s / 0s\n",
      "TRAIN    loss : 0.00025    F1 : 1.00000\n",
      "epoch : 25 / 25    time : 0s / 0s\n",
      "TRAIN    loss : 0.00021    F1 : 1.00000\n"
     ]
    }
   ],
   "source": [
    "def score_function(real, pred):\n",
    "    score = f1_score(real, pred, average = \"macro\")\n",
    "    return score\n",
    "\n",
    "model = Network().to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 1e-3)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "scaler = torch.cuda.amp.GradScaler() \n",
    "\n",
    "\n",
    "\n",
    "best = 0\n",
    "for epoch in range(epochs):\n",
    "    start = time.time()\n",
    "    train_loss = 0\n",
    "    train_pred = []\n",
    "    train_y = []\n",
    "    model.train()\n",
    "    for batch in (train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        x = torch.tensor(batch[0], dtype = torch.float32, device=device)\n",
    "        y = torch.tensor(batch[1], dtype = torch.long, device=device)\n",
    "        with torch.cuda.amp.autocast():\n",
    "            pred = model(x)\n",
    "        loss = criterion(pred, y)\n",
    "\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        \n",
    "        train_loss += loss.item() / len(train_loader)\n",
    "        train_pred += pred.argmax(1).detach().cpu().numpy().tolist()\n",
    "        train_y += y.detach().cpu().numpy().tolist()\n",
    "        \n",
    "    \n",
    "    train_f1 = score_function(train_y, train_pred)\n",
    "\n",
    "    TIME = time.time() - start\n",
    "    print(f'epoch : {epoch + 1} / {epochs}    time : {TIME:.0f}s / {TIME*(epochs - epoch - 1):.0f}s')\n",
    "    print(f'TRAIN    loss : {train_loss:.5f}    F1 : {train_f1:.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "f_pred = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in (test_loader):\n",
    "        x = torch.tensor(batch[0], dtype = torch.float32, device = device)\n",
    "        with torch.cuda.amp.autocast():\n",
    "            pred = model(x)\n",
    "        f_pred.extend(pred.argmax(1).detach().cpu().numpy().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "pred_sum = 0\n",
    "for i in f_pred:\n",
    "    pred_sum = pred_sum + i\n",
    "print(pred_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0, 1: 1}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_decoder = {val:key for key, val in label_unique.items()}\n",
    "label_decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "12",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32md:\\thon\\DL\\zindi_highly_imbal_effnetb0_pytorch.ipynb Cell 13'\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/thon/DL/zindi_highly_imbal_effnetb0_pytorch.ipynb#ch0000011?line=0'>1</a>\u001b[0m label_decoder \u001b[39m=\u001b[39m {val:key \u001b[39mfor\u001b[39;00m key, val \u001b[39min\u001b[39;00m label_unique\u001b[39m.\u001b[39mitems()}\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/thon/DL/zindi_highly_imbal_effnetb0_pytorch.ipynb#ch0000011?line=2'>3</a>\u001b[0m f_result \u001b[39m=\u001b[39m [label_decoder[result] \u001b[39mfor\u001b[39;00m result \u001b[39min\u001b[39;00m f_pred]\n",
      "\u001b[1;32md:\\thon\\DL\\zindi_highly_imbal_effnetb0_pytorch.ipynb Cell 13'\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/thon/DL/zindi_highly_imbal_effnetb0_pytorch.ipynb#ch0000011?line=0'>1</a>\u001b[0m label_decoder \u001b[39m=\u001b[39m {val:key \u001b[39mfor\u001b[39;00m key, val \u001b[39min\u001b[39;00m label_unique\u001b[39m.\u001b[39mitems()}\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/thon/DL/zindi_highly_imbal_effnetb0_pytorch.ipynb#ch0000011?line=2'>3</a>\u001b[0m f_result \u001b[39m=\u001b[39m [label_decoder[result] \u001b[39mfor\u001b[39;00m result \u001b[39min\u001b[39;00m f_pred]\n",
      "\u001b[1;31mKeyError\u001b[0m: 12"
     ]
    }
   ],
   "source": [
    "label_decoder = {val:key for key, val in label_unique.items()}\n",
    "\n",
    "f_result = [label_decoder[result] for result in f_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image_id</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_00exusbkgzw1b.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_03dqinf6w0znv.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_046yl0cxn3ybz.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_04athdtx2abyg.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_062aauf9e9jk0.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1075</th>\n",
       "      <td>id_zv5fvjnakvf1r.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1076</th>\n",
       "      <td>id_zvpikh1z30arn.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1077</th>\n",
       "      <td>id_zypilwkudljyz.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1078</th>\n",
       "      <td>id_zz9lwehh5sxdp.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1079</th>\n",
       "      <td>id_zzq9gaptlwd4w.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1080 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Image_id  Label\n",
       "0     id_00exusbkgzw1b.jpg      0\n",
       "1     id_03dqinf6w0znv.jpg      0\n",
       "2     id_046yl0cxn3ybz.jpg      0\n",
       "3     id_04athdtx2abyg.jpg      0\n",
       "4     id_062aauf9e9jk0.jpg      0\n",
       "...                    ...    ...\n",
       "1075  id_zv5fvjnakvf1r.jpg      0\n",
       "1076  id_zvpikh1z30arn.jpg      0\n",
       "1077  id_zypilwkudljyz.jpg      0\n",
       "1078  id_zz9lwehh5sxdp.jpg      0\n",
       "1079  id_zzq9gaptlwd4w.jpg      0\n",
       "\n",
       "[1080 rows x 2 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.read_csv(\"./zindi/SampleSubmission.csv\")\n",
    "submission[\"Label\"] = f_pred\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1079"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(submission['Label'] == )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('Sub_imbal_b0.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "542 1080\n"
     ]
    }
   ],
   "source": [
    "perfect = pd.read_csv('./zindi/submission_csv/Perfect_AUC.csv')\n",
    "\n",
    "print(np.sum(submission[\"Label\"] == perfect['Label']), len(submission[\"Label\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5018518518518519"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "542/1080"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "453dee3dc3901cb9a21ed0866384fb1d6a0d6f4710a79aa791e402cd59be06a2"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('tf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
