{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "\n",
    "import os\n",
    "import timm\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from sklearn.metrics import f1_score, accuracy_score, roc_auc_score\n",
    "import time\n",
    "\n",
    "\n",
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input your own directory\n",
    "\n",
    "file_dir = 'D:/thon/DL/zindi'\n",
    "img_dir = file_dir + '/Images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(file_dir + \"/Train.csv\")\n",
    "test_df = pd.read_csv(file_dir + '/Test.csv')\n",
    "train_labels = train_df[\"Label\"]\n",
    "\n",
    "label_unique = sorted(np.unique(train_labels))\n",
    "label_unique = {key:value for key,value in zip(label_unique, range(len(label_unique)))}\n",
    "\n",
    "train_labels = [label_unique[k] for k in train_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "### You don't need to do it twice\n",
    "\n",
    "# Generate new 'train', 'test' image folders in your file_directory\n",
    "\n",
    "os.makedirs(img_dir + '/train')\n",
    "os.makedirs(img_dir + '/test')\n",
    "\n",
    "# Set train and test directories\n",
    "\n",
    "train_dir = img_dir + '/train'\n",
    "test_dir = img_dir + '/test'\n",
    "\n",
    "### To move files according to train.csv and test.csv's 'Image_id' column\n",
    "\n",
    "train_file_name = train_df[\"Image_id\"]\n",
    "train_file_label = train_df[\"Label\"]\n",
    "test_file_name = test_df[\"Image_id\"]\n",
    "\n",
    "# Move train images from 'Images' folder to 'train' folder\n",
    "\n",
    "for i in train_file_name:\n",
    "    file_source = img_dir + f'/{i}'\n",
    "    file_destination = train_dir\n",
    "    shutil.move(file_source, file_destination)\n",
    "\n",
    "\n",
    "# Move test images from 'Images' folder to 'test' folder\n",
    "\n",
    "for i in test_file_name:\n",
    "    file_source = img_dir + f'/{i}'\n",
    "    file_destination = test_dir\n",
    "    shutil.move(file_source, file_destination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_jpg = sorted(glob(train_dir +'/*.jpg'))\n",
    "test_jpg = sorted(glob(test_dir + '/*.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = 224 # input size for efficientnet_b0 : 224 * 224\n",
    "\n",
    "def img_load(path):\n",
    "    img = cv2.imread(path)[:,:,::-1]\n",
    "    img = cv2.resize(img, (img_size, img_size))\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1619/1619 [00:23<00:00, 68.11it/s]\n",
      "100%|██████████| 1080/1080 [00:15<00:00, 70.10it/s]\n"
     ]
    }
   ],
   "source": [
    "train_imgs = [img_load(m) for m in tqdm(train_jpg)]\n",
    "test_imgs = [img_load(n) for n in tqdm(test_jpg)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Custom_dataset(Dataset):\n",
    "    def __init__(self, img_paths, labels, mode='train'):\n",
    "        self.img_paths = img_paths\n",
    "        self.labels = labels\n",
    "        self.mode=mode\n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)\n",
    "    def __getitem__(self, idx):\n",
    "        img = self.img_paths[idx]\n",
    "        if self.mode=='train':\n",
    "            augmentation = random.randint(0,2)\n",
    "            if augmentation==1:\n",
    "                img = img[::-1].copy()\n",
    "            elif augmentation==2:\n",
    "                img = img[:,::-1].copy()\n",
    "        img = transforms.ToTensor()(img)\n",
    "        if self.mode=='test':\n",
    "            pass\n",
    "        \n",
    "        label = self.labels[idx]\n",
    "        return img, label\n",
    "    \n",
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Network, self).__init__()\n",
    "        self.model = timm.create_model('efficientnet_b0', pretrained=True, num_classes=88)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "epochs = 25\n",
    "\n",
    "# Train\n",
    "train_dataset = Custom_dataset(np.array(train_imgs), np.array(train_labels), mode='train')\n",
    "train_loader = DataLoader(train_dataset, shuffle=True, batch_size=batch_size)\n",
    "\n",
    "# Test\n",
    "test_dataset = Custom_dataset(np.array(test_imgs), np.array([\"tmp\"]*len(test_imgs)), mode='test')\n",
    "test_loader = DataLoader(test_dataset, shuffle=False, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1/25    time : 19s/464s\n",
      "TRAIN    loss : 0.46129    f1 : 0.92170\n",
      "epoch : 2/25    time : 14s/316s\n",
      "TRAIN    loss : 0.04454    f1 : 0.98888\n",
      "epoch : 3/25    time : 14s/304s\n",
      "TRAIN    loss : 0.02314    f1 : 0.99197\n",
      "epoch : 4/25    time : 14s/290s\n",
      "TRAIN    loss : 0.05213    f1 : 0.98456\n",
      "epoch : 5/25    time : 14s/278s\n",
      "TRAIN    loss : 0.02688    f1 : 0.99321\n",
      "epoch : 6/25    time : 14s/263s\n",
      "TRAIN    loss : 0.00886    f1 : 0.99753\n",
      "epoch : 7/25    time : 14s/251s\n",
      "TRAIN    loss : 0.00214    f1 : 0.99938\n",
      "epoch : 8/25    time : 14s/238s\n",
      "TRAIN    loss : 0.00371    f1 : 0.99815\n",
      "epoch : 9/25    time : 14s/225s\n",
      "TRAIN    loss : 0.01079    f1 : 0.99629\n",
      "epoch : 10/25    time : 14s/210s\n",
      "TRAIN    loss : 0.02092    f1 : 0.99382\n",
      "epoch : 11/25    time : 14s/196s\n",
      "TRAIN    loss : 0.00277    f1 : 0.99938\n",
      "epoch : 12/25    time : 14s/183s\n",
      "TRAIN    loss : 0.03383    f1 : 0.99074\n",
      "epoch : 13/25    time : 14s/170s\n",
      "TRAIN    loss : 0.02401    f1 : 0.99321\n",
      "epoch : 14/25    time : 14s/155s\n",
      "TRAIN    loss : 0.00435    f1 : 0.99938\n",
      "epoch : 15/25    time : 14s/141s\n",
      "TRAIN    loss : 0.00177    f1 : 0.99938\n",
      "epoch : 16/25    time : 14s/126s\n",
      "TRAIN    loss : 0.00057    f1 : 1.00000\n",
      "epoch : 17/25    time : 14s/112s\n",
      "TRAIN    loss : 0.00029    f1 : 1.00000\n",
      "epoch : 18/25    time : 14s/98s\n",
      "TRAIN    loss : 0.00016    f1 : 1.00000\n",
      "epoch : 19/25    time : 14s/84s\n",
      "TRAIN    loss : 0.00005    f1 : 1.00000\n",
      "epoch : 20/25    time : 14s/70s\n",
      "TRAIN    loss : 0.00019    f1 : 1.00000\n",
      "epoch : 21/25    time : 14s/56s\n",
      "TRAIN    loss : 0.00017    f1 : 1.00000\n",
      "epoch : 22/25    time : 14s/42s\n",
      "TRAIN    loss : 0.00013    f1 : 1.00000\n",
      "epoch : 23/25    time : 14s/28s\n",
      "TRAIN    loss : 0.00013    f1 : 1.00000\n",
      "epoch : 24/25    time : 14s/14s\n",
      "TRAIN    loss : 0.00131    f1 : 1.00000\n",
      "epoch : 25/25    time : 14s/0s\n",
      "TRAIN    loss : 0.00009    f1 : 1.00000\n"
     ]
    }
   ],
   "source": [
    "def score_function(real, pred):\n",
    "    score = roc_auc_score(real, pred, average=\"macro\")\n",
    "    return score\n",
    "\n",
    "model = Network().to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "scaler = torch.cuda.amp.GradScaler() \n",
    "\n",
    "\n",
    "\n",
    "best=0\n",
    "for epoch in range(epochs):\n",
    "    start=time.time()\n",
    "    train_loss = 0\n",
    "    train_pred=[]\n",
    "    train_y=[]\n",
    "    model.train()\n",
    "    for batch in (train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        x = torch.tensor(batch[0], dtype=torch.float32, device=device)\n",
    "        y = torch.tensor(batch[1], dtype=torch.long, device=device)\n",
    "        with torch.cuda.amp.autocast():\n",
    "            pred = model(x)\n",
    "        loss = criterion(pred, y)\n",
    "\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        \n",
    "        train_loss += loss.item()/len(train_loader)\n",
    "        train_pred += pred.argmax(1).detach().cpu().numpy().tolist()\n",
    "        train_y += y.detach().cpu().numpy().tolist()\n",
    "        \n",
    "    \n",
    "    train_auc = score_function(train_y, train_pred)\n",
    "\n",
    "    TIME = time.time() - start\n",
    "    print(f'epoch : {epoch+1}/{epochs}    time : {TIME:.0f}s/{TIME*(epochs-epoch-1):.0f}s')\n",
    "    print(f'TRAIN    loss : {train_loss:.5f}    AUC : {train_auc:.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "f_pred = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in (test_loader):\n",
    "        x = torch.tensor(batch[0], dtype = torch.float32, device = device)\n",
    "        with torch.cuda.amp.autocast():\n",
    "            pred = model(x)\n",
    "        f_pred.extend(pred.argmax(1).detach().cpu().numpy().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_decoder = {val:key for key, val in label_unique.items()}\n",
    "\n",
    "f_result = [label_decoder[result] for result in f_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image_id</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_00exusbkgzw1b.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_03dqinf6w0znv.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_046yl0cxn3ybz.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_04athdtx2abyg.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_062aauf9e9jk0.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1075</th>\n",
       "      <td>id_zv5fvjnakvf1r.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1076</th>\n",
       "      <td>id_zvpikh1z30arn.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1077</th>\n",
       "      <td>id_zypilwkudljyz.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1078</th>\n",
       "      <td>id_zz9lwehh5sxdp.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1079</th>\n",
       "      <td>id_zzq9gaptlwd4w.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1080 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Image_id  Label\n",
       "0     id_00exusbkgzw1b.jpg      0\n",
       "1     id_03dqinf6w0znv.jpg      0\n",
       "2     id_046yl0cxn3ybz.jpg      1\n",
       "3     id_04athdtx2abyg.jpg      0\n",
       "4     id_062aauf9e9jk0.jpg      0\n",
       "...                    ...    ...\n",
       "1075  id_zv5fvjnakvf1r.jpg      1\n",
       "1076  id_zvpikh1z30arn.jpg      0\n",
       "1077  id_zypilwkudljyz.jpg      0\n",
       "1078  id_zz9lwehh5sxdp.jpg      1\n",
       "1079  id_zzq9gaptlwd4w.jpg      1\n",
       "\n",
       "[1080 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.read_csv(\"./zindi/SampleSubmission.csv\")\n",
    "submission[\"Label\"] = f_result\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('Submission_v2.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "453dee3dc3901cb9a21ed0866384fb1d6a0d6f4710a79aa791e402cd59be06a2"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('tf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
