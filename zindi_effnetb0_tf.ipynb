{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zindi Image classification (Binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as img # to read images\n",
    "\n",
    "import os                      # to generate new file directories\n",
    "import shutil                  # to move files\n",
    "from tqdm import tqdm          # to see process bar\n",
    "import argparse\n",
    "\n",
    "\n",
    "import glob                    # to gather jpg files\n",
    "from glob import glob\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.preprocessing.image import load_img\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\" # Use GPU:0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def auto_select_accelerator():\n",
    "    try:\n",
    "        tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "        tf.config.experimental_connect_to_cluster(tpu)\n",
    "        tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "        strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "        print(\"Running on TPU:\", tpu.master())\n",
    "    except ValueError:\n",
    "        strategy = tf.distribute.get_strategy()\n",
    "    print(f\"Running on {strategy.num_replicas_in_sync} replicas\")\n",
    "    return strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on 1 replicas\n"
     ]
    }
   ],
   "source": [
    "strategy = auto_select_accelerator()\n",
    "REPLICAS = strategy.num_replicas_in_sync\n",
    "AUTO = tf.data.experimental.AUTOTUNE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input your own file directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input your file directory\n",
    "\n",
    "file_dir = 'D:/thon/DL/zindi' # Change here with your file directory\n",
    "\n",
    "img_dir = file_dir + '/Images'\n",
    "\n",
    "train_dir = img_dir + '/train'\n",
    "test_dir = img_dir + '/test'\n",
    "\n",
    "train1_dir = train_dir + '/1'\n",
    "train0_dir = train_dir + '/0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1619\n",
      "               Image_id  Label\n",
      "0  id_02amazy34fgh2.jpg      1\n",
      "1  id_02mh3w48pmyc9.jpg      0\n",
      "2  id_02rpb463h9d3w.jpg      0\n",
      "3  id_02wc3jeeao8ol.jpg      1\n",
      "4  id_03t2hapb8wz8p.jpg      1\n",
      "\n",
      "\n",
      "               Image_id\n",
      "0  id_00exusbkgzw1b.jpg\n",
      "1  id_03dqinf6w0znv.jpg\n",
      "2  id_046yl0cxn3ybz.jpg\n",
      "3  id_04athdtx2abyg.jpg\n",
      "4  id_062aauf9e9jk0.jpg\n",
      "\n",
      "\n",
      "1080\n",
      "1080\n"
     ]
    }
   ],
   "source": [
    "# Read train, test and submission csv files\n",
    "\n",
    "train_df = pd.read_csv(file_dir + '/Train.csv')\n",
    "test_df = pd.read_csv(file_dir + '/Test.csv')\n",
    "sample_sub = pd.read_csv(file_dir + '/SampleSubmission.csv')\n",
    "\n",
    "print(len(train_df['Image_id']))\n",
    "print(train_df.head())\n",
    "print('\\n')\n",
    "print(test_df.head())\n",
    "print('\\n')\n",
    "print(len(test_df['Image_id']))\n",
    "print(np.sum(test_df['Image_id'] == sample_sub['Image_id'])) # Test.csv and SampleSubmission.csv's Image_id is identical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1619 files belonging to 2 classes.\n",
      "Using 1296 files for training.\n",
      "\n",
      "\n",
      "Found 1619 files belonging to 2 classes.\n",
      "Using 323 files for validation.\n",
      "\n",
      "\n",
      "Found 1080 files belonging to 1 classes.\n",
      "\n",
      "\n",
      "['0', '1']\n",
      "\n",
      "\n",
      "The shape of image is (64, 224, 224, 3)\n",
      "The shape of labels is (64, 1)\n"
     ]
    }
   ],
   "source": [
    "### Image preprocessing\n",
    "# Set batch_size, img_height, img_width\n",
    "\n",
    "batch_size = 64\n",
    "img_size = 224 # EfficientNetB0 uses input shape (224, 224, 3)\n",
    "channels = 3\n",
    "size = (img_size, img_size)\n",
    "\n",
    "# Train image dataset\n",
    "\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    train_dir,\n",
    "    validation_split = 0.2, # 1619 * 0.8 = 1296 images are for train dataset\n",
    "    label_mode = 'binary',\n",
    "    subset = 'training',\n",
    "    shuffle = True,\n",
    "    seed = 2021120087,\n",
    "    image_size = size,\n",
    "    batch_size = batch_size)\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "# Validation image dataset\n",
    "\n",
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    train_dir,\n",
    "    validation_split = 0.2, # 1619 * 0.2 = 323 images are for validation dataset\n",
    "    label_mode = 'binary',\n",
    "    subset = \"validation\",\n",
    "    shuffle = True,\n",
    "    seed = 2021120087,\n",
    "    image_size = size,\n",
    "    batch_size = batch_size)\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "# Test image dataset\n",
    "\n",
    "test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    test_dir,\n",
    "    label_mode = None,\n",
    "    shuffle = False,\n",
    "    image_size = size,\n",
    "    batch_size = batch_size)\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "# Check the train image shapes\n",
    "\n",
    "class_names = train_ds.class_names\n",
    "print(class_names)\n",
    "num_classes = len(class_names)\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "for image_batch, labels_batch in train_ds:\n",
    "    print(\"The shape of image is\", image_batch.shape)\n",
    "    print(\"The shape of labels is\", labels_batch.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds_unbatch = train_ds.unbatch()\n",
    "train_ds_label = list(train_ds_unbatch.map(lambda x, y: y))\n",
    "train_ds_img = list(train_ds_unbatch.map(lambda x, y: x))\n",
    "\n",
    "val_ds_unbatch = val_ds.unbatch()\n",
    "val_ds_label = list(val_ds_unbatch.map(lambda x, y: y))\n",
    "val_ds_img = list(val_ds_unbatch.map(lambda x, y: x))\n",
    "\n",
    "train_ds_one_hot_label = to_categorical(train_ds_label)\n",
    "val_ds_one_hot_label = to_categorical(val_ds_label)\n",
    "\n",
    "train_ds = tf.data.Dataset.from_tensor_slices({\"img\" : train_ds_img, \"label\" : train_ds_one_hot_label})\n",
    "val_ds = tf.data.Dataset.from_tensor_slices({\"img\" : val_ds_img, \"label\" : val_ds_one_hot_label})\n",
    "\n",
    "train_ds = train_ds.batch(batch_size)\n",
    "val_ds = val_ds.batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "train_ds_unbatch = train_ds.unbatch()\n",
    "train_ds_label = list(train_ds_unbatch.map(lambda x, y: y))\n",
    "train_ds_img = list(train_ds_unbatch.map(lambda x, y: x))\n",
    "\n",
    "val_ds_unbatch = val_ds.unbatch()\n",
    "val_ds_label = list(val_ds_unbatch.map(lambda x, y: y))\n",
    "val_ds_img = list(val_ds_unbatch.map(lambda x, y: x))\n",
    "\n",
    "train_ds_one_hot_label = to_categorical(train_ds_label)\n",
    "val_ds_one_hot_label = to_categorical(val_ds_label)\n",
    "\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((train_ds_img, train_ds_one_hot_label))\n",
    "val_ds = tf.data.Dataset.from_tensor_slices((val_ds_img, val_ds_one_hot_label))\n",
    "\n",
    "train_ds = train_ds.batch(batch_size)\n",
    "val_ds = val_ds.batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow.keras.layers' has no attribute 'RandomRotation'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32md:\\thon\\DL\\zindi_efficientnet.ipynb Cell 12'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/thon/DL/zindi_efficientnet.ipynb#ch0000024?line=0'>1</a>\u001b[0m img_augmentation \u001b[39m=\u001b[39m Sequential(\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/thon/DL/zindi_efficientnet.ipynb#ch0000024?line=1'>2</a>\u001b[0m     [\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/thon/DL/zindi_efficientnet.ipynb#ch0000024?line=2'>3</a>\u001b[0m         layers\u001b[39m.\u001b[39;49mRandomRotation(factor\u001b[39m=\u001b[39m\u001b[39m0.15\u001b[39m),\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/thon/DL/zindi_efficientnet.ipynb#ch0000024?line=3'>4</a>\u001b[0m         layers\u001b[39m.\u001b[39mRandomTranslation(height_factor\u001b[39m=\u001b[39m\u001b[39m0.1\u001b[39m, width_factor\u001b[39m=\u001b[39m\u001b[39m0.1\u001b[39m),\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/thon/DL/zindi_efficientnet.ipynb#ch0000024?line=4'>5</a>\u001b[0m         layers\u001b[39m.\u001b[39mRandomFlip(),\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/thon/DL/zindi_efficientnet.ipynb#ch0000024?line=5'>6</a>\u001b[0m         layers\u001b[39m.\u001b[39mRandomContrast(factor\u001b[39m=\u001b[39m\u001b[39m0.1\u001b[39m),\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/thon/DL/zindi_efficientnet.ipynb#ch0000024?line=6'>7</a>\u001b[0m     ],\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/thon/DL/zindi_efficientnet.ipynb#ch0000024?line=7'>8</a>\u001b[0m     name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mimg_augmentation\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/thon/DL/zindi_efficientnet.ipynb#ch0000024?line=8'>9</a>\u001b[0m )\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'tensorflow.keras.layers' has no attribute 'RandomRotation'"
     ]
    }
   ],
   "source": [
    "img_augmentation = Sequential(\n",
    "    [\n",
    "        layers.RandomRotation(factor=0.15),\n",
    "        layers.RandomTranslation(height_factor=0.1, width_factor=0.1),\n",
    "        layers.RandomFlip(),\n",
    "        layers.RandomContrast(factor=0.1),\n",
    "    ],\n",
    "    name=\"img_augmentation\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Model using tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_15 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "efficientnetb0 (Functional)  (None, 2)                 4052133   \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 3         \n",
      "=================================================================\n",
      "Total params: 4,052,136\n",
      "Trainable params: 4,010,113\n",
      "Non-trainable params: 42,023\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# ConvNet layers\n",
    "\n",
    "inputs = keras.Input(shape = (img_size, img_size, channels))\n",
    "x = tf.keras.applications.EfficientNetB0(weights = None, classes = num_classes)(inputs)\n",
    "outputs = layers.Dense(1, activation = 'sigmoid')(x)\n",
    "\n",
    "model = tf.keras.Model(inputs = inputs, outputs = outputs)\n",
    "\n",
    "model.compile(\n",
    "    optimizer = 'adam',\n",
    "    loss = tf.losses.BinaryCrossentropy(),\n",
    "    metrics = ['Accuracy']\n",
    ")\n",
    "\n",
    "\n",
    "# Model summary\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": " OOM when allocating tensor with shape[40,144,1,1] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node model_7/efficientnetb0/block3a_project_conv/Conv2D (defined at \\AppData\\Local\\Temp\\ipykernel_14908\\890731201.py:3) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n [Op:__inference_train_function_124106]\n\nFunction call stack:\ntrain_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32md:\\thon\\DL\\zindi_efficientnet.ipynb Cell 15'\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/thon/DL/zindi_efficientnet.ipynb#ch0000014?line=0'>1</a>\u001b[0m \u001b[39m# Train model\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/thon/DL/zindi_efficientnet.ipynb#ch0000014?line=2'>3</a>\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(train_ds, validation_data \u001b[39m=\u001b[39;49m val_ds, epochs \u001b[39m=\u001b[39;49m \u001b[39m20\u001b[39;49m, batch_size \u001b[39m=\u001b[39;49m batch_size)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1183\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/sujin/anaconda3/envs/tf/lib/site-packages/tensorflow/python/keras/engine/training.py?line=1175'>1176</a>\u001b[0m \u001b[39mwith\u001b[39;00m trace\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   <a href='file:///c%3A/Users/sujin/anaconda3/envs/tf/lib/site-packages/tensorflow/python/keras/engine/training.py?line=1176'>1177</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m   <a href='file:///c%3A/Users/sujin/anaconda3/envs/tf/lib/site-packages/tensorflow/python/keras/engine/training.py?line=1177'>1178</a>\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   <a href='file:///c%3A/Users/sujin/anaconda3/envs/tf/lib/site-packages/tensorflow/python/keras/engine/training.py?line=1178'>1179</a>\u001b[0m     step_num\u001b[39m=\u001b[39mstep,\n\u001b[0;32m   <a href='file:///c%3A/Users/sujin/anaconda3/envs/tf/lib/site-packages/tensorflow/python/keras/engine/training.py?line=1179'>1180</a>\u001b[0m     batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[0;32m   <a href='file:///c%3A/Users/sujin/anaconda3/envs/tf/lib/site-packages/tensorflow/python/keras/engine/training.py?line=1180'>1181</a>\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[0;32m   <a href='file:///c%3A/Users/sujin/anaconda3/envs/tf/lib/site-packages/tensorflow/python/keras/engine/training.py?line=1181'>1182</a>\u001b[0m   callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> <a href='file:///c%3A/Users/sujin/anaconda3/envs/tf/lib/site-packages/tensorflow/python/keras/engine/training.py?line=1182'>1183</a>\u001b[0m   tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   <a href='file:///c%3A/Users/sujin/anaconda3/envs/tf/lib/site-packages/tensorflow/python/keras/engine/training.py?line=1183'>1184</a>\u001b[0m   \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   <a href='file:///c%3A/Users/sujin/anaconda3/envs/tf/lib/site-packages/tensorflow/python/keras/engine/training.py?line=1184'>1185</a>\u001b[0m     context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:889\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/sujin/anaconda3/envs/tf/lib/site-packages/tensorflow/python/eager/def_function.py?line=885'>886</a>\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    <a href='file:///c%3A/Users/sujin/anaconda3/envs/tf/lib/site-packages/tensorflow/python/eager/def_function.py?line=887'>888</a>\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> <a href='file:///c%3A/Users/sujin/anaconda3/envs/tf/lib/site-packages/tensorflow/python/eager/def_function.py?line=888'>889</a>\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    <a href='file:///c%3A/Users/sujin/anaconda3/envs/tf/lib/site-packages/tensorflow/python/eager/def_function.py?line=890'>891</a>\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    <a href='file:///c%3A/Users/sujin/anaconda3/envs/tf/lib/site-packages/tensorflow/python/eager/def_function.py?line=891'>892</a>\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:917\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/sujin/anaconda3/envs/tf/lib/site-packages/tensorflow/python/eager/def_function.py?line=913'>914</a>\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    <a href='file:///c%3A/Users/sujin/anaconda3/envs/tf/lib/site-packages/tensorflow/python/eager/def_function.py?line=914'>915</a>\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/sujin/anaconda3/envs/tf/lib/site-packages/tensorflow/python/eager/def_function.py?line=915'>916</a>\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Users/sujin/anaconda3/envs/tf/lib/site-packages/tensorflow/python/eager/def_function.py?line=916'>917</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateless_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/sujin/anaconda3/envs/tf/lib/site-packages/tensorflow/python/eager/def_function.py?line=917'>918</a>\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/Users/sujin/anaconda3/envs/tf/lib/site-packages/tensorflow/python/eager/def_function.py?line=918'>919</a>\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/sujin/anaconda3/envs/tf/lib/site-packages/tensorflow/python/eager/def_function.py?line=919'>920</a>\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/sujin/anaconda3/envs/tf/lib/site-packages/tensorflow/python/eager/def_function.py?line=920'>921</a>\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3023\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/sujin/anaconda3/envs/tf/lib/site-packages/tensorflow/python/eager/function.py?line=3019'>3020</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m   <a href='file:///c%3A/Users/sujin/anaconda3/envs/tf/lib/site-packages/tensorflow/python/eager/function.py?line=3020'>3021</a>\u001b[0m   (graph_function,\n\u001b[0;32m   <a href='file:///c%3A/Users/sujin/anaconda3/envs/tf/lib/site-packages/tensorflow/python/eager/function.py?line=3021'>3022</a>\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> <a href='file:///c%3A/Users/sujin/anaconda3/envs/tf/lib/site-packages/tensorflow/python/eager/function.py?line=3022'>3023</a>\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m   <a href='file:///c%3A/Users/sujin/anaconda3/envs/tf/lib/site-packages/tensorflow/python/eager/function.py?line=3023'>3024</a>\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1960\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/sujin/anaconda3/envs/tf/lib/site-packages/tensorflow/python/eager/function.py?line=1955'>1956</a>\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   <a href='file:///c%3A/Users/sujin/anaconda3/envs/tf/lib/site-packages/tensorflow/python/eager/function.py?line=1956'>1957</a>\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   <a href='file:///c%3A/Users/sujin/anaconda3/envs/tf/lib/site-packages/tensorflow/python/eager/function.py?line=1957'>1958</a>\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   <a href='file:///c%3A/Users/sujin/anaconda3/envs/tf/lib/site-packages/tensorflow/python/eager/function.py?line=1958'>1959</a>\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> <a href='file:///c%3A/Users/sujin/anaconda3/envs/tf/lib/site-packages/tensorflow/python/eager/function.py?line=1959'>1960</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   <a href='file:///c%3A/Users/sujin/anaconda3/envs/tf/lib/site-packages/tensorflow/python/eager/function.py?line=1960'>1961</a>\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   <a href='file:///c%3A/Users/sujin/anaconda3/envs/tf/lib/site-packages/tensorflow/python/eager/function.py?line=1961'>1962</a>\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   <a href='file:///c%3A/Users/sujin/anaconda3/envs/tf/lib/site-packages/tensorflow/python/eager/function.py?line=1962'>1963</a>\u001b[0m     args,\n\u001b[0;32m   <a href='file:///c%3A/Users/sujin/anaconda3/envs/tf/lib/site-packages/tensorflow/python/eager/function.py?line=1963'>1964</a>\u001b[0m     possible_gradient_type,\n\u001b[0;32m   <a href='file:///c%3A/Users/sujin/anaconda3/envs/tf/lib/site-packages/tensorflow/python/eager/function.py?line=1964'>1965</a>\u001b[0m     executing_eagerly)\n\u001b[0;32m   <a href='file:///c%3A/Users/sujin/anaconda3/envs/tf/lib/site-packages/tensorflow/python/eager/function.py?line=1965'>1966</a>\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:591\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/sujin/anaconda3/envs/tf/lib/site-packages/tensorflow/python/eager/function.py?line=588'>589</a>\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    <a href='file:///c%3A/Users/sujin/anaconda3/envs/tf/lib/site-packages/tensorflow/python/eager/function.py?line=589'>590</a>\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> <a href='file:///c%3A/Users/sujin/anaconda3/envs/tf/lib/site-packages/tensorflow/python/eager/function.py?line=590'>591</a>\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    <a href='file:///c%3A/Users/sujin/anaconda3/envs/tf/lib/site-packages/tensorflow/python/eager/function.py?line=591'>592</a>\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    <a href='file:///c%3A/Users/sujin/anaconda3/envs/tf/lib/site-packages/tensorflow/python/eager/function.py?line=592'>593</a>\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    <a href='file:///c%3A/Users/sujin/anaconda3/envs/tf/lib/site-packages/tensorflow/python/eager/function.py?line=593'>594</a>\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    <a href='file:///c%3A/Users/sujin/anaconda3/envs/tf/lib/site-packages/tensorflow/python/eager/function.py?line=594'>595</a>\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    <a href='file:///c%3A/Users/sujin/anaconda3/envs/tf/lib/site-packages/tensorflow/python/eager/function.py?line=595'>596</a>\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    <a href='file:///c%3A/Users/sujin/anaconda3/envs/tf/lib/site-packages/tensorflow/python/eager/function.py?line=596'>597</a>\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/Users/sujin/anaconda3/envs/tf/lib/site-packages/tensorflow/python/eager/function.py?line=597'>598</a>\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    <a href='file:///c%3A/Users/sujin/anaconda3/envs/tf/lib/site-packages/tensorflow/python/eager/function.py?line=598'>599</a>\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    <a href='file:///c%3A/Users/sujin/anaconda3/envs/tf/lib/site-packages/tensorflow/python/eager/function.py?line=599'>600</a>\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/sujin/anaconda3/envs/tf/lib/site-packages/tensorflow/python/eager/function.py?line=602'>603</a>\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    <a href='file:///c%3A/Users/sujin/anaconda3/envs/tf/lib/site-packages/tensorflow/python/eager/function.py?line=603'>604</a>\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:59\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/sujin/anaconda3/envs/tf/lib/site-packages/tensorflow/python/eager/execute.py?line=56'>57</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     <a href='file:///c%3A/Users/sujin/anaconda3/envs/tf/lib/site-packages/tensorflow/python/eager/execute.py?line=57'>58</a>\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> <a href='file:///c%3A/Users/sujin/anaconda3/envs/tf/lib/site-packages/tensorflow/python/eager/execute.py?line=58'>59</a>\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     <a href='file:///c%3A/Users/sujin/anaconda3/envs/tf/lib/site-packages/tensorflow/python/eager/execute.py?line=59'>60</a>\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     <a href='file:///c%3A/Users/sujin/anaconda3/envs/tf/lib/site-packages/tensorflow/python/eager/execute.py?line=60'>61</a>\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     <a href='file:///c%3A/Users/sujin/anaconda3/envs/tf/lib/site-packages/tensorflow/python/eager/execute.py?line=61'>62</a>\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m:  OOM when allocating tensor with shape[40,144,1,1] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node model_7/efficientnetb0/block3a_project_conv/Conv2D (defined at \\AppData\\Local\\Temp\\ipykernel_14908\\890731201.py:3) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n [Op:__inference_train_function_124106]\n\nFunction call stack:\ntrain_function\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "\n",
    "history = model.fit(train_ds, validation_data = val_ds, epochs = 20, batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize validation loss and accuracy loss\n",
    "\n",
    "history_dict = history.history\n",
    "loss_values = history_dict[\"loss\"]\n",
    "val_loss_values = history_dict[\"val_loss\"]\n",
    "epochs = range(1, len(loss_values) + 1)\n",
    "plt.plot(epochs, loss_values, \"bo\", label = \"Training loss\")\n",
    "plt.plot(epochs, val_loss_values, \"b\", label = \"Validation loss\")\n",
    "plt.title(\"Training and validation loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To find the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "41/41 [==============================] - 5s 95ms/step - loss: 0.6567 - auc: 0.6537 - val_loss: 0.6228 - val_auc: 0.8502\n",
      "Epoch 2/50\n",
      "41/41 [==============================] - 4s 91ms/step - loss: 0.5060 - auc: 0.8363 - val_loss: 0.4167 - val_auc: 0.8943\n",
      "Epoch 3/50\n",
      "41/41 [==============================] - 4s 91ms/step - loss: 0.4145 - auc: 0.8975 - val_loss: 0.3216 - val_auc: 0.9382\n",
      "Epoch 4/50\n",
      "41/41 [==============================] - 4s 92ms/step - loss: 0.2874 - auc: 0.9493 - val_loss: 0.2627 - val_auc: 0.9662\n",
      "Epoch 5/50\n",
      "41/41 [==============================] - 4s 91ms/step - loss: 0.2172 - auc: 0.9709 - val_loss: 0.2686 - val_auc: 0.9531\n",
      "Epoch 6/50\n",
      "41/41 [==============================] - 4s 90ms/step - loss: 0.1767 - auc: 0.9805 - val_loss: 0.1984 - val_auc: 0.9843\n",
      "Epoch 7/50\n",
      "41/41 [==============================] - 4s 91ms/step - loss: 0.1405 - auc: 0.9871 - val_loss: 0.1855 - val_auc: 0.9794\n",
      "Epoch 8/50\n",
      "41/41 [==============================] - 4s 91ms/step - loss: 0.1104 - auc: 0.9928 - val_loss: 0.1548 - val_auc: 0.9885\n",
      "Epoch 9/50\n",
      "41/41 [==============================] - 4s 91ms/step - loss: 0.0772 - auc: 0.9959 - val_loss: 0.1604 - val_auc: 0.9876\n",
      "Epoch 10/50\n",
      "41/41 [==============================] - 4s 91ms/step - loss: 0.0770 - auc: 0.9967 - val_loss: 0.1489 - val_auc: 0.9875\n",
      "Epoch 11/50\n",
      "41/41 [==============================] - 4s 91ms/step - loss: 0.0476 - auc: 0.9988 - val_loss: 0.1702 - val_auc: 0.9850\n",
      "Epoch 12/50\n",
      "41/41 [==============================] - 4s 91ms/step - loss: 0.0646 - auc: 0.9976 - val_loss: 0.1706 - val_auc: 0.9867\n",
      "Epoch 13/50\n",
      "41/41 [==============================] - 4s 90ms/step - loss: 0.0270 - auc: 0.9997 - val_loss: 0.1537 - val_auc: 0.9869\n",
      "Epoch 14/50\n",
      "41/41 [==============================] - 4s 91ms/step - loss: 0.0178 - auc: 0.9999 - val_loss: 0.1762 - val_auc: 0.9847\n",
      "Epoch 15/50\n",
      "41/41 [==============================] - 4s 90ms/step - loss: 0.0083 - auc: 1.0000 - val_loss: 0.2074 - val_auc: 0.9789\n",
      "Epoch 16/50\n",
      "41/41 [==============================] - 4s 91ms/step - loss: 0.0332 - auc: 0.9993 - val_loss: 0.1966 - val_auc: 0.9789\n",
      "Epoch 17/50\n",
      "41/41 [==============================] - 4s 92ms/step - loss: 0.0094 - auc: 1.0000 - val_loss: 0.1962 - val_auc: 0.9808\n",
      "Epoch 18/50\n",
      "41/41 [==============================] - 4s 93ms/step - loss: 0.0031 - auc: 1.0000 - val_loss: 0.2345 - val_auc: 0.9750\n",
      "Epoch 19/50\n",
      "41/41 [==============================] - 4s 91ms/step - loss: 8.1195e-04 - auc: 1.0000 - val_loss: 0.2372 - val_auc: 0.9781\n",
      "Epoch 20/50\n",
      "41/41 [==============================] - 4s 92ms/step - loss: 4.8156e-04 - auc: 1.0000 - val_loss: 0.2527 - val_auc: 0.9778\n",
      "Epoch 21/50\n",
      "41/41 [==============================] - 4s 92ms/step - loss: 2.5683e-04 - auc: 1.0000 - val_loss: 0.2509 - val_auc: 0.9783\n",
      "Epoch 22/50\n",
      "41/41 [==============================] - 4s 94ms/step - loss: 1.9915e-04 - auc: 1.0000 - val_loss: 0.2589 - val_auc: 0.9760\n",
      "Epoch 23/50\n",
      "41/41 [==============================] - 4s 96ms/step - loss: 1.5207e-04 - auc: 1.0000 - val_loss: 0.2663 - val_auc: 0.9735\n",
      "Epoch 24/50\n",
      "41/41 [==============================] - 4s 92ms/step - loss: 1.1980e-04 - auc: 1.0000 - val_loss: 0.2739 - val_auc: 0.9735\n",
      "Epoch 25/50\n",
      "41/41 [==============================] - 4s 90ms/step - loss: 9.7082e-05 - auc: 1.0000 - val_loss: 0.2834 - val_auc: 0.9734\n",
      "Epoch 26/50\n",
      "41/41 [==============================] - 4s 91ms/step - loss: 8.1829e-05 - auc: 1.0000 - val_loss: 0.2933 - val_auc: 0.9736\n",
      "Epoch 27/50\n",
      "41/41 [==============================] - 4s 90ms/step - loss: 6.8242e-05 - auc: 1.0000 - val_loss: 0.2964 - val_auc: 0.9706\n",
      "Epoch 28/50\n",
      "41/41 [==============================] - 4s 90ms/step - loss: 5.7005e-05 - auc: 1.0000 - val_loss: 0.3092 - val_auc: 0.9738\n",
      "Epoch 29/50\n",
      "41/41 [==============================] - 4s 91ms/step - loss: 5.3676e-05 - auc: 1.0000 - val_loss: 0.3099 - val_auc: 0.9709\n",
      "Epoch 30/50\n",
      "41/41 [==============================] - 4s 91ms/step - loss: 4.3339e-05 - auc: 1.0000 - val_loss: 0.3207 - val_auc: 0.9712\n",
      "Epoch 31/50\n",
      "41/41 [==============================] - 4s 91ms/step - loss: 4.4777e-05 - auc: 1.0000 - val_loss: 0.3237 - val_auc: 0.9711\n",
      "Epoch 32/50\n",
      "41/41 [==============================] - 4s 90ms/step - loss: 3.6875e-05 - auc: 1.0000 - val_loss: 0.3334 - val_auc: 0.9711\n",
      "Epoch 33/50\n",
      "41/41 [==============================] - 4s 93ms/step - loss: 3.7643e-05 - auc: 1.0000 - val_loss: 0.3310 - val_auc: 0.9711\n",
      "Epoch 34/50\n",
      "41/41 [==============================] - 4s 94ms/step - loss: 2.9721e-05 - auc: 1.0000 - val_loss: 0.3356 - val_auc: 0.9711\n",
      "Epoch 35/50\n",
      "41/41 [==============================] - 4s 92ms/step - loss: 2.5816e-05 - auc: 1.0000 - val_loss: 0.3368 - val_auc: 0.9711\n",
      "Epoch 36/50\n",
      "41/41 [==============================] - 4s 95ms/step - loss: 2.2278e-05 - auc: 1.0000 - val_loss: 0.3476 - val_auc: 0.9686\n",
      "Epoch 37/50\n",
      "41/41 [==============================] - 4s 92ms/step - loss: 2.1186e-05 - auc: 1.0000 - val_loss: 0.3517 - val_auc: 0.9712\n",
      "Epoch 38/50\n",
      "41/41 [==============================] - 4s 91ms/step - loss: 1.8822e-05 - auc: 1.0000 - val_loss: 0.3552 - val_auc: 0.9686\n",
      "Epoch 39/50\n",
      "41/41 [==============================] - 4s 91ms/step - loss: 1.6891e-05 - auc: 1.0000 - val_loss: 0.3603 - val_auc: 0.9686\n",
      "Epoch 40/50\n",
      "41/41 [==============================] - 4s 91ms/step - loss: 1.5348e-05 - auc: 1.0000 - val_loss: 0.3659 - val_auc: 0.9686\n",
      "Epoch 41/50\n",
      "41/41 [==============================] - 4s 90ms/step - loss: 1.4932e-05 - auc: 1.0000 - val_loss: 0.3721 - val_auc: 0.9658\n",
      "Epoch 42/50\n",
      "41/41 [==============================] - 4s 91ms/step - loss: 1.4576e-05 - auc: 1.0000 - val_loss: 0.3694 - val_auc: 0.9686\n",
      "Epoch 43/50\n",
      "41/41 [==============================] - 4s 91ms/step - loss: 1.1574e-05 - auc: 1.0000 - val_loss: 0.3747 - val_auc: 0.9686\n",
      "Epoch 44/50\n",
      "41/41 [==============================] - 4s 91ms/step - loss: 1.0128e-05 - auc: 1.0000 - val_loss: 0.3828 - val_auc: 0.9659\n",
      "Epoch 45/50\n",
      "41/41 [==============================] - 4s 92ms/step - loss: 9.9060e-06 - auc: 1.0000 - val_loss: 0.3752 - val_auc: 0.9686\n",
      "Epoch 46/50\n",
      "41/41 [==============================] - 4s 91ms/step - loss: 9.0840e-06 - auc: 1.0000 - val_loss: 0.3897 - val_auc: 0.9658\n",
      "Epoch 47/50\n",
      "41/41 [==============================] - 4s 93ms/step - loss: 8.2325e-06 - auc: 1.0000 - val_loss: 0.3937 - val_auc: 0.9659\n",
      "Epoch 48/50\n",
      "41/41 [==============================] - 4s 92ms/step - loss: 7.3322e-06 - auc: 1.0000 - val_loss: 0.3946 - val_auc: 0.9659\n",
      "Epoch 49/50\n",
      "41/41 [==============================] - 4s 92ms/step - loss: 6.3875e-06 - auc: 1.0000 - val_loss: 0.4034 - val_auc: 0.9661\n",
      "Epoch 50/50\n",
      "41/41 [==============================] - 4s 90ms/step - loss: 5.8387e-06 - auc: 1.0000 - val_loss: 0.4148 - val_auc: 0.9634\n"
     ]
    }
   ],
   "source": [
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath = \"convnet.keras\", # Save the best model as 'convnet.kears'\n",
    "        save_best_only = True,\n",
    "        monitor = \"val_loss\")\n",
    "]\n",
    "\n",
    "history_test = model.fit(\n",
    "    train_ds,\n",
    "    epochs = 50,\n",
    "    validation_data = val_ds,\n",
    "    callbacks = callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image_id</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_00exusbkgzw1b.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_03dqinf6w0znv.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_046yl0cxn3ybz.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_04athdtx2abyg.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_062aauf9e9jk0.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Image_id  Label\n",
       "0  id_00exusbkgzw1b.jpg      0\n",
       "1  id_03dqinf6w0znv.jpg      0\n",
       "2  id_046yl0cxn3ybz.jpg      1\n",
       "3  id_04athdtx2abyg.jpg      0\n",
       "4  id_062aauf9e9jk0.jpg      0"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the best model\n",
    "\n",
    "test_model = keras.models.load_model(\"convnet.keras\") # load the best model which we defined \"convnet.keras\"\n",
    "\n",
    "predictions = test_model.predict(test_ds)\n",
    "prediction_classes = [\n",
    "    1 if prob > 0.5 else 0 for prob in np.ravel(predictions)\n",
    "]\n",
    "\n",
    "sample_sub[\"Label\"] = prediction_classes\n",
    "sample_sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save csv file\n",
    "\n",
    "sample_sub.to_csv(\"Submission.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "453dee3dc3901cb9a21ed0866384fb1d6a0d6f4710a79aa791e402cd59be06a2"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('tf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
